<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>maps_news Platform: Spec & Plan</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            background-color: #f5f5f4; /* stone-100 */
            color: #292524; /* stone-800 */
        }
        .spec-content h1, .spec-content h2, .spec-content h3 {
            font-weight: bold;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }
        .spec-content h1 { font-size: 1.875rem; color: #1c1917; } /* stone-900 */
        .spec-content h2 { font-size: 1.5rem; color: #292524; border-bottom: 1px solid #d6d3d1; padding-bottom: 0.25rem;} /* stone-800, stone-300 */
        .spec-content h3 { font-size: 1.25rem; color: #44403c; } /* stone-700 */
        .spec-content ul { list-style-type: disc; margin-left: 1.5rem; margin-bottom: 1rem; }
        .spec-content li { margin-bottom: 0.25rem; }
        .spec-content code { background-color: #e7e5e4; padding: 0.1rem 0.3rem; border-radius: 0.25rem; font-family: monospace; } /* stone-200 */
        .spec-content strong { font-weight: bold; }
        .spec-content em { font-style: italic; }
    </style>
</head>
<body class="font-sans antialiased">

    <div class="max-w-full mx-auto p-4 sm:p-6 lg:p-8">
        <header class="text-center mb-10">
            <h1 class="text-4xl md:text-5xl font-bold text-stone-900">maps_news Platform</h1>
            <p class="mt-2 text-lg text-stone-600">Software Specification & Interactive Plan</p>
        </header>

        <main class="grid grid-cols-1 lg:grid-cols-2 gap-8 h-[calc(100vh-150px)]">
            <!-- Specification Column -->
            <div class="bg-white p-6 rounded-lg shadow-sm border border-stone-200 overflow-y-auto">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-bold text-stone-800">Software Specification (v4.2)</h2>
                    <a href="plan.html" target="_blank" class="text-sm text-blue-600 hover:underline">View Plan in New Tab</a>
                </div>
                <div id="spec-container" class="spec-content">
                    <!-- Spec content will be injected here -->
                </div>
            </div>

            <!-- Plan Column -->
            <div class="rounded-lg shadow-sm border border-stone-200 overflow-hidden h-full">
                <iframe src="plan.html" class="w-full h-full border-0"></iframe>
            </div>
        </main>
    </div>

    <script>
        const markdownContent = `
## Final Software Specification (v4.2)

This document outlines a content analysis and NLP platform, moving from data ingestion and transformation (ETL) to automated analysis and user-facing interaction.

### 1. Technology Stack Summary

* **Backend (Core):** **FastAPI**
* **Database:** **SQLite** (development), **PostgreSQL** (production)
* **Database ORM:** **SQLAlchemy**
* **NLP (Core):** **spaCy**
* **NLP (Models):** spaCy models for **English** (e.g., \`en_core_web_sm\`) and **Spanish** (e.g., \`es_core_news_sm\`)
* **Clustering/ML:** **scikit-learn**
* **OCR:** **Tesseract**
* **Backend Task Queue:** **Celery & Redis**

### 2. User Personas

* \`Admin\`: Configures and monitors the ingestion pipeline; schedules and monitors the NLP analysis jobs.
* \`Data Analyst\`: Logs in to search, view, and annotate content; consumes the *results* of the automated NLP jobs.

### 3. Functional Requirements (User Stories)

#### Module 1: The Data Pipeline (Ingestion & Storage)

* **Story 1 (Extract):** As an \`Admin\`, I want to configure sources, which can be websites, RSS feeds, or local directories containing files (\`.txt\`, \`.md\`, \`.csv\`, \`.docx\`, \`.xlsx\`, \`.pdf\`, \`.jpg\`, \`.png\`, \`.webp\`).
    * **1a (OCR):** As an \`Admin\`, when the pipeline detects an image (\`.jpg\`, \`.png\`, \`.webp\`), I want the system to automatically run **Tesseract** to extract text.
    * **1b (Parsers):** As an \`Admin\`, I want the system to use the correct parser for each file type (\`.pdf\`, \`.docx\`, etc.).
    * **1c (Excel Handling):** As an \`Admin\`, when the pipeline detects an \`.xlsx\` file, I want the system to first convert it to an in-memory \`.csv\` representation.
* **Story 2 (Schedule):** As an \`Admin\`, I want to be able to schedule ingestion jobs to run at specific intervals.
* **Story 3 (Transform):** As an \`Admin\`, I want the system to sanitize and transform all extracted content into a standardized "Article" data model.
    * **3a (Structured Data):** **(Updated)** For \`.csv\` and converted \`.xlsx\` files, each **row** must be treated as a separate document and stored in the \`content_text\` field of a **new, distinct \`Article\` entity**.
* **Story 4 (Load):** As an \`Admin\`, I want the transformed "Article" data to be loaded and indexed (for full-text search) into the **PostgreSQL database**.
* **Story 5 (Audit):** As an \`Admin\`, I want to view a detailed pipeline activity log, filterable by date, source, and status (Success/Failure).

---

#### Module 2: The Content Application (Interaction)

* **Story 6 (Auth):** As a user, I want to log in with a username and password. The system must **only grant access if my account is marked as \`is_active\`**.
* **Story 7 (Search):** As a \`Data Analyst\`, I want to perform a full-text search (using PostgreSQL's built-in FTS) across the content of all articles.
* **Story 8 (Filter):** As a \`Data Analyst\`, I want to filter my search results by metadata (source, date range, tags).
* **Story 9 (View):** As a \`Data Analyst\`, I want to open a search result to view the clean, transformed article content.
* **Story 10 (Annotate - Tag):** As a \`Data Analyst\`, I want to be able to add one or more **tags** to any article.
* **Story 11 (Annotate - Comment):** As a \`Data Analyst\`, I want to be able to add free-text **comments** or notes to an article.
* **Story 12 (Export):** As a \`Data Analyst\`, I want to be able to select one or more articles and **export** them (e.g., as CSV or JSON).

---

#### Module 3: The Data Analysis (Automated Processing)

* **Story 13 (Job Scheduling):** As an \`Admin\`, I want to schedule all major NLP jobs (NER, Clustering, Association Rules) to run automatically at a defined interval (e.g., nightly).
* **Story 14 (Job Scope):** As the **System**, when a scheduled NLP job runs, it must **only process articles** that have a \`last_nlp_run_timestamp\` older than the start time of the *previous* job, ensuring no documents are skipped and work is not duplicated.
* **Story 15 (Job Status):** As a \`Data Analyst\`, I want to see a "Last Analysis Run" timestamp in the UI so I know how fresh the NLP data (entities, clusters) is.
* **Story 16 (View Word Cloud):** **(Updated)** As a \`Data Analyst\`, I want to select one or more articles and request a **word cloud**. The system must generate this asynchronously (using the **Celery** queue) and notify the UI when the visualization is ready.
* **Story 17 (View NER):** As a \`Data Analyst\`, I want to view the list of named entities (People, Orgs, etc.) that were **automatically extracted** by the last scheduled **spaCy** job for any given article.
* **Story 18 (View Clusters):** As a \`Data Analyst\`, I want to be able to view the topic or entity clusters (generated by **scikit-learn**) and see all articles that belong to a specific cluster.
* **Story 19 (View Rules):** As a \`Data Analyst\`, I want to browse the **association rules** generated by the last scheduled job (e.g., "See terms most associated with 'Project X'").

---

#### Module 4: Administration & Management (CLI)

* **Story 20 (Database Init):** As an \`Admin\`, I want to run a single command... to create the database...
* **Story 21 (Add User):** As an \`Admin\`, I want a CLI command to create a new user by providing a username, a password, and a role (\`admin\` or \`data_analyst\`).
* **Story 22 (Toggle User):** As an \`Admin\`, I want a CLI command to **deactivate (block)** or **reactivate (unblock)** a user by their username. This command will toggle their \`is_active\` status.
* **Story 23 (Add Source):** As an \`Admin\`, I want a CLI command to add a new data source...
* **Story 24 (Toggle Source):** As an \`Admin\`, I want a CLI command to block (deactivate) or unblock (reactivate) a specific data source.

### 4. Relational Data Model (PostgreSQL)

* \`User\`:
    * \`user_id\` (PK)
    * \`username\` (Unique)
    * \`hashed_password\`
    * \`role\` ('admin', 'data_analyst')
    * \`is_active\` (Boolean, default: true)
* \`Source\`:
    * \`source_id\` (PK)
    * \`name\`, \`type\`, \`location\`, \`last_run_timestamp\`
* \`Article\`:
    * \`article_id\` (PK)
    * \`source_id\` (FK to \`Source\`, ON DELETE SET NULL)
    * \`title\`, \`content_text\`, \`original_url\`
    * \`source_format\` (e.g., 'pdf', 'rss', 'csv-row', 'png')
    * \`extraction_date\`
    * \`content_text_vector\` (A \`tsvector\` column for FTS)
    * \`last_nlp_run_timestamp\` (Timestamp, nullable. Used by Story 14)
* \`Annotation\`:
    * \`annotation_id\` (PK)
    * \`article_id\` (FK to \`Article\`, **ON DELETE CASCADE**)
    * \`user_id\` (FK to \`User\`, ON DELETE SET NULL)
    * \`type\` ('TAG', 'COMMENT'), \`content\`, \`created_at\`
* \`NamedEntity\`:
    * \`entity_id\` (PK)
    * \`entity_text\` (e.g., "Google"), \`entity_type\` (e.g., 'ORG'), \`language\` ('en' or 'es')
* \`ArticleEntity\`: (Join table)
    * \`article_id\` (FK to \`Article\`, **ON DELETE CASCADE**)
    * \`entity_id\` (FK to \`NamedEntity\`, **ON DELETE CASCADE**)
* \`Cluster\`:
    * \`cluster_id\` (PK)
    * \`cluster_name\` (e.g., "Topic 1: Finance"), \`cluster_type\` ('TOPIC', 'ENTITY'), \`last_run_id\`
* \`ArticleCluster\`: (Join table)
    * \`article_id\` (FK to \`Article\`, **ON DELETE CASCADE**)
    * \`cluster_id\` (FK to \`Cluster\`, **ON DELETE CASCADE**)
* \`PipelineLog\`: (Unchanged)

### 5. Non-Functional Requirements (NFRs)

1.  **Database:** Must use **SQLite** for development and **PostgreSQL** for production.
2.  **Search:** Full-text search must use **PostgreSQL's native FTS** (\`tsvector\`/\`tsquery\`).
3.  **Asynchronous Processing:** All Module 3 NLP jobs **must** run as asynchronous background tasks on a schedule, separate from the web application.
4.  **Multi-language:** The NLP pipeline must load and use **spaCy** models for both **English** and **Spanish** to process documents.
5.  **OCR:** The system must use **Tesseract** for all image-to-text extraction.
6.  **Fault-Tolerance:** The ingestion pipeline must log errors from a single failed source (e.g., 404 URL) and continue processing the rest of the sources.
7.  **(New) Configuration:** All application settings, including database connections, source locations, and queue credentials, must be managed externally via **YAML configuration files**.
8.  **(New) Testing (Coverage):** The system must have >80% unit test coverage.
9.  **(New) Testing (Integration):** All pipeline parsers must have integration tests.
10. **(New) Testing (UI):** UI tests must cover the login and search workflows.
11. **(New) Security (Auth):** All web application endpoints must be secured, requiring an authenticated session.
12. **(New) Security (Transport):** The system must use SSL/TLS in production.
13. **(New) Security (CLI):** Admin CLI scripts must require authenticated credentials.
`;

        function markdownToHtml(md) {
            let html = md;

            // Headings
            html = html.replace(/^### (.*$)/gim, '<h3>$1</h3>');
            html = html.replace(/^## (.*$)/gim, '<h2>$1</h2>');
            html = html.replace(/^# (.*$)/gim, '<h1>$1</h1>');

            // Bold and Italic from asterisks
            html = html.replace(/\*\*\*(.*?)\*\*\*/gim, '<strong><em>$1</em></strong>');
            html = html.replace(/\*\*(.*?)\*\*/gim, '<strong>$1</strong>');
            html = html.replace(/\*(.*?)\*/gim, '<em>$1</em>');

            // Lists
            html = html.replace(/^\* (.*$)/gim, '<ul><li>$1</li></ul>');
            html = html.replace(/<\/ul>\n<ul>/gim, ''); // Merge consecutive lists

            // Inline Code
            html = html.replace(/`(.*?)`/gim, '<code>$1</code>');

            // Horizontal Rule
            html = html.replace(/^---$/gim, '<hr class="my-6 border-stone-200">');

            // Line breaks
            html = html.replace(/\n/g, '<br>');

            return html;
        }


        document.addEventListener('DOMContentLoaded', () => {
            const specContainer = document.getElementById('spec-container');
            // A simple conversion for display purposes. For full markdown support, a library would be better.
            specContainer.innerHTML = markdownToHtml(markdownContent.trim());
        });

    </script>
</body>
</html>
